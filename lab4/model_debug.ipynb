{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crf import CRF\n",
    "from transformers import RobertaModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List, Tuple\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import log_softmax\n",
    "import evaluate\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "@dataclass\n",
    "class Instance:\n",
    "\twords: List[str]\n",
    "\tori_words: List[str]\n",
    "\tlabels: List[str] = None\n",
    "\tprediction: List[str]  = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTA_PATH = '/home/dzigen/Desktop/medics2023/NLP_MODULE/models/RuBioRoBERTa'\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = 'cuda'\n",
    "EPOCHS = 30\n",
    "LAYERS_TO_HOLD = ['23', '22', '21', 'pooler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-L1', 'I-L1', 'B-L2', 'I-L2', 'B-L3', 'I-L3', 'B-L4', 'I-L4', 'B-L5', 'I-L5', 'B-L6', 'I-L6', 'B-L7', 'I-L7', 'B-L8', 'I-L8', 'B-L9', 'I-L9', 'B-L10', 'I-L10', 'B-L11', 'I-L11', 'B-L12', 'I-L12', 'B-L13', 'I-L13', 'B-L14', 'I-L14']\n",
      "{'O': 0, 'B-L1': 1, 'I-L1': 2, 'B-L2': 3, 'I-L2': 4, 'B-L3': 5, 'I-L3': 6, 'B-L4': 7, 'I-L4': 8, 'B-L5': 9, 'I-L5': 10, 'B-L6': 11, 'I-L6': 12, 'B-L7': 13, 'I-L7': 14, 'B-L8': 15, 'I-L8': 16, 'B-L9': 17, 'I-L9': 18, 'B-L10': 19, 'I-L10': 20, 'B-L11': 21, 'I-L11': 22, 'B-L12': 23, 'I-L12': 24, 'B-L13': 25, 'I-L13': 26, 'B-L14': 27, 'I-L14': 28}\n",
      "{0: 'O', 1: 'B-L1', 2: 'I-L1', 3: 'B-L2', 4: 'I-L2', 5: 'B-L3', 6: 'I-L3', 7: 'B-L4', 8: 'I-L4', 9: 'B-L5', 10: 'I-L5', 11: 'B-L6', 12: 'I-L6', 13: 'B-L7', 14: 'I-L7', 15: 'B-L8', 16: 'I-L8', 17: 'B-L9', 18: 'I-L9', 19: 'B-L10', 20: 'I-L10', 21: 'B-L11', 22: 'I-L11', 23: 'B-L12', 24: 'I-L12', 25: 'B-L13', 26: 'I-L13', 27: 'B-L14', 28: 'I-L14'}\n"
     ]
    }
   ],
   "source": [
    "tagged_names = [\"КТР\",\"ЧСС\",\"ТВП\",\"ТРИКУСП РЕГУРГ\",\"ХГЧ\",\"PAPP-A\",\"АФП\",\n",
    "                \"Ингибин А\",\"св эстрадиол\",\"Возраст\",\"Вес\",\"Рост\",\"ИМТ\",\"ФК\"]\n",
    "\n",
    "LABEL_LIST = ['O']\n",
    "for i, f_name in enumerate(tagged_names):\n",
    "    f_b, f_i = f\"B-L{i+1}\", f\"I-L{i+1}\"\n",
    "    LABEL_LIST.append(f_b)\n",
    "    LABEL_LIST.append(f_i)\n",
    "print(LABEL_LIST)\n",
    "\n",
    "LABEL2ID = {label: i for i, label in enumerate(LABEL_LIST)}\n",
    "ID2LABEL = {i: label for i, label in enumerate(LABEL_LIST)}\n",
    "\n",
    "print(LABEL2ID)\n",
    "print(ID2LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = json.loads(open(\"./test_metrics.json\", 'r', encoding='utf-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11077"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_metrics['true_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaCrf(nn.Module):\n",
    "    def __init__(self,num_labels: int,base_path: str,):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.roberta = RobertaModel.from_pretrained(base_path)\n",
    "\n",
    "        # Замораживаем часть слоёв бекбона\n",
    "        for name, param in self.roberta.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        for name, param in self.roberta.named_parameters():\n",
    "            for hold_l in LAYERS_TO_HOLD:\n",
    "                if hold_l in name:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.hidden2label = nn.Linear(self.roberta.config.hidden_size, num_labels)\n",
    "\n",
    "        self.start_transitions = nn.Parameter(torch.empty(num_labels))\n",
    "        self.end_transitions = nn.Parameter(torch.empty(num_labels))\n",
    "        self.transitions = nn.Parameter(torch.empty(num_labels, num_labels))\n",
    "\n",
    "        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.end_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.transitions, -0.1, 0.1)\n",
    "\n",
    "    def _compute_log_denominator(self, features: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "        seq_len = features.shape[0]\n",
    "\n",
    "        log_score_over_all_seq = self.start_transitions + features[0]\n",
    "\n",
    "        for i in range(1, seq_len):\n",
    "            next_log_score_over_all_seq = torch.logsumexp(\n",
    "                log_score_over_all_seq.unsqueeze(2) + self.transitions + features[i].unsqueeze(1),\n",
    "                dim=1,\n",
    "            )\n",
    "            log_score_over_all_seq = torch.where(\n",
    "                mask[i].unsqueeze(1),\n",
    "                next_log_score_over_all_seq,\n",
    "                log_score_over_all_seq,\n",
    "            )\n",
    "        log_score_over_all_seq += self.end_transitions\n",
    "        return torch.logsumexp(log_score_over_all_seq, dim=1)\n",
    "\n",
    "    def _compute_log_numerator(self, features: torch.Tensor, labels: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
    "        seq_len, bs, _ = features.shape\n",
    "\n",
    "        score_over_seq = self.start_transitions[labels[0]] + features[0, torch.arange(bs), labels[0]]\n",
    "\n",
    "        for i in range(1, seq_len):\n",
    "            score_over_seq += (\n",
    "                self.transitions[labels[i - 1], labels[i]] + features[i, torch.arange(bs), labels[i]]\n",
    "            ) * mask[i]\n",
    "        seq_lens = mask.sum(dim=0) - 1\n",
    "        last_tags = labels[seq_lens.long(), torch.arange(bs)]\n",
    "        score_over_seq += self.end_transitions[last_tags]\n",
    "        return score_over_seq\n",
    "\n",
    "    def get_roberta_features(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        hidden = self.roberta(input_ids, attention_mask=attention_mask)[\"last_hidden_state\"]\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.hidden2label(hidden), hidden\n",
    "\n",
    "    def forward(self,input_ids: torch.Tensor,\n",
    "                attention_mask: torch.Tensor,labels: torch.Tensor,) -> torch.Tensor:\n",
    "        features, _ = self.get_roberta_features(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        attention_mask = attention_mask.bool()\n",
    "\n",
    "        features = torch.swapaxes(features, 0, 1)\n",
    "        attention_mask = torch.swapaxes(attention_mask, 0, 1)\n",
    "        labels = torch.swapaxes(labels, 0, 1)\n",
    "\n",
    "        log_numerator = self._compute_log_numerator(features=features, labels=labels, mask=attention_mask)\n",
    "        log_denominator = self._compute_log_denominator(features=features, mask=attention_mask)\n",
    "\n",
    "        return torch.mean(log_denominator - log_numerator)\n",
    "\n",
    "\n",
    "    def _viterbi_decode(self, features: torch.Tensor, mask: torch.Tensor) -> List[List[int]]:\n",
    "        seq_len, bs, _ = features.shape\n",
    "\n",
    "        log_score_over_all_seq = self.start_transitions + features[0]\n",
    "\n",
    "        backpointers = torch.empty_like(features)\n",
    "\n",
    "        for i in range(1, seq_len):\n",
    "            next_log_score_over_all_seq = (\n",
    "                log_score_over_all_seq.unsqueeze(2) + self.transitions + features[i].unsqueeze(1)\n",
    "            )\n",
    "\n",
    "            next_log_score_over_all_seq, indices = next_log_score_over_all_seq.max(dim=1)\n",
    "\n",
    "            log_score_over_all_seq = torch.where(\n",
    "                mask[i].unsqueeze(1),\n",
    "                next_log_score_over_all_seq,\n",
    "                log_score_over_all_seq,\n",
    "            )\n",
    "            backpointers[i] = indices\n",
    "\n",
    "        backpointers = backpointers[1:].int()\n",
    "\n",
    "        log_score_over_all_seq += self.end_transitions\n",
    "        seq_lens = mask.sum(dim=0) - 1\n",
    "\n",
    "        best_paths = []\n",
    "        for seq_ind in range(bs):\n",
    "            best_label_id = torch.argmax(log_score_over_all_seq[seq_ind]).item()\n",
    "            best_path = [best_label_id]\n",
    "\n",
    "            for backpointer in reversed(backpointers[: seq_lens[seq_ind]]):\n",
    "                best_path.append(backpointer[seq_ind][best_path[-1]].item())\n",
    "\n",
    "            best_path.reverse()\n",
    "            best_paths.append(best_path)\n",
    "\n",
    "        return best_paths\n",
    "\n",
    "    def decode(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> List[List[int]]:\n",
    "        features, _ = self.get_roberta_features(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        attention_mask = attention_mask.bool()\n",
    "\n",
    "        features = torch.swapaxes(features, 0, 1)\n",
    "        mask = torch.swapaxes(attention_mask, 0, 1)\n",
    "        return self._viterbi_decode(features=features, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaCRF(nn.Module):\n",
    "    def __init__(self, label_size, roberta_path=ROBERTA_PATH, device=DEVICE):\n",
    "        super(RobertaCRF, self).__init__()\n",
    "\n",
    "        self.encoder = RobertaModel.from_pretrained(roberta_path).to(device)\n",
    "        self.dropout = nn.Dropout(0.5)     \n",
    "        self.linear = nn.Linear(self.encoder.config.hidden_size, label_size)\n",
    "        self.crf = CRF(label_size)\n",
    "\n",
    "        # Замораживаем часть слоёв бекбона\n",
    "        for name, param in self.encoder.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        for name, param in self.encoder.named_parameters():\n",
    "            for hold_l in LAYERS_TO_HOLD:\n",
    "                if hold_l in name:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None, mode='train'):\n",
    "        embeddings = self.encoder(input_ids=input_ids, attention_mask= attention_mask)\n",
    "        drop_out = self.dropout(embeddings.last_hidden_state)\n",
    "        linear_out = self.linear(drop_out)\n",
    "\n",
    "        if mode == 'train':\n",
    "            crf_out = self.crf(linear_out, mask=attention_mask, \n",
    "                               labels=labels)\n",
    "        elif mode == 'eval':\n",
    "            crf_out = self.crf.viterbi_decode(linear_out, mask=attention_mask)\n",
    "        else:\n",
    "            raise KeyError\n",
    "        \n",
    "        return crf_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_MODEL_PATH = '/home/dzigen/Desktop/ITMO/sem1/DLtech/dl_tech_learn/lab4/saved_model/ner_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = AutoTokenizer.from_pretrained(ROBERTA_PATH, add_prefix_space=True, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = RobertaCrf(len(LABEL_LIST), ROBERTA_PATH).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = RobertaCRF(len(LABEL_LIST)).to(DEVICE)\n",
    "\n",
    "MODEL.load_state_dict(torch.load(FINETUNED_MODEL_PATH))\n",
    "MODEL.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_MODEL_PATH = \"/home/dzigen/Desktop/medics2023/NLP_MODULE/models/tagged/ner_model_epoch5\"\n",
    "MODEL = RobertaForTokenClassification.from_pretrained(ROBERTA_PATH, id2label=ID2LABEL, label2id=LABEL2ID).to(DEVICE)\n",
    "MODEL.load_state_dict(torch.load(FINETUNED_MODEL_PATH))\n",
    "MODEL.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file, label2idx, tokenizer):\n",
    "        \"\"\"\n",
    "        sents: we use sentences if we want to build dataset from sentences directly instead of file\n",
    "        \"\"\"\n",
    "        ## read all the instances. sentences and labels\n",
    "        insts = self.read_file(file=file) \n",
    "        self.insts = insts\n",
    "        self.label2idx = label2idx\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        len_input_ids = [\n",
    "            len(self.tokenizer(self.insts[i].words, is_split_into_words=True)['input_ids']) \n",
    "            for i in range(len(self.insts))\n",
    "            ]\n",
    "        long_samples_ids = sorted(list(map(lambda vv: vv[0], filter(lambda v: v[1] > 512, enumerate(len_input_ids)))), reverse=True)\n",
    "        for long_train_id in long_samples_ids:\n",
    "            del self.insts[long_train_id]\n",
    "        print(f\"{len(long_samples_ids)} samples was deletet because its long len\")\n",
    "\n",
    "    def read_file(self, file: str, number: int = -1) -> List[Instance]:\n",
    "        insts = []\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            words = []\n",
    "            ori_words = []\n",
    "            labels = []\n",
    "            for line in tqdm(f.readlines()):\n",
    "                line = line.rstrip()\n",
    "                if line == \"\":\n",
    "                    insts.append(Instance(words=words, ori_words=ori_words, labels=labels))\n",
    "                    words = []\n",
    "                    ori_words = []\n",
    "                    labels = []\n",
    "                    if len(insts) == number:\n",
    "                        break\n",
    "                    continue\n",
    "                ls = line.split()\n",
    "                word, label = ls[0],ls[-1]\n",
    "                ori_words.append(word)\n",
    "                words.append(word)\n",
    "                labels.append(label)\n",
    "        return insts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.insts)\n",
    "    \n",
    "    def tokenize_and_align_labels(self, example, label_all_tokens = True):\n",
    "        tokenized_inputs = TOKENIZER(example.words, truncation=True, padding='max_length', max_length=512, \n",
    "                                     is_split_into_words=True)\n",
    "\n",
    "        word_ids = tokenized_inputs.word_ids()\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to 0 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(0)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(example.labels[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or 0, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(example.labels[word_idx] if label_all_tokens else 0)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        tokenized_inputs[\"labels\"] = list(map(lambda v: LABEL2ID.get(v, 0), label_ids))\n",
    "        return tokenized_inputs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.tokenize_and_align_labels(self.insts[index])\n",
    "        return {'input_ids': torch.tensor(item['input_ids']), \n",
    "                'attention_mask': torch.ByteTensor(item['attention_mask']),\n",
    "                'labels': torch.tensor(item['labels'])}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FILE = '/home/dzigen/Desktop/ITMO/sem1/DLtech/dl_tech_learn/lab4/medics/train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9166325/9166325 [00:04<00:00, 1932499.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 samples was deletet because its long len\n"
     ]
    }
   ],
   "source": [
    "test_ds = NerDataset(TEST_FILE,LABEL_LIST,TOKENIZER)\n",
    "test_dataloader = DataLoader(test_ds, shuffle=False, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_metrics(accum_preds, accum_refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = MODEL(batch1['input_ids'].to(DEVICE), \n",
    "               attention_mask=batch1['attention_mask'].to(DEVICE), mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda acc, v: acc + [v], [1,2,3,4], [5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, labels):\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = reduce(lambda acc, v: acc + v, \n",
    "                              [[p for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)], [])\n",
    "    true_labels = reduce(lambda acc, v: acc + v, \n",
    "                         [[l for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)], [])\n",
    "\n",
    "    return { \"f1_micro\": f1_score(true_predictions, true_labels, average=\"micro\"),\n",
    "             \"f1_weighted\": f1_score(true_predictions, true_labels, average=\"weighted\"),\n",
    "             \"accuracy\": accuracy_score(true_predictions, true_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics([[0,0,0,0]],[[0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/11073 [00:02<6:17:48,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_micro': 1.0, 'f1_weighted': 1.0, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/11073 [00:04<6:12:31,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_micro': 1.0, 'f1_weighted': 1.0, 'accuracy': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/11073 [00:05<8:19:43,  2.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(test_dataloader):\n\u001b[1;32m      5\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m         output \u001b[39m=\u001b[39m MODEL(input_ids\u001b[39m=\u001b[39;49mbatch[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mto(DEVICE), attention_mask\u001b[39m=\u001b[39;49mbatch[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mto(DEVICE), mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39meval\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m     preds \u001b[39m=\u001b[39m output\n\u001b[1;32m      8\u001b[0m     refs \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36mRobertaCRF.forward\u001b[0;34m(self, input_ids, attention_mask, labels, mode)\u001b[0m\n\u001b[1;32m     24\u001b[0m     crf_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrf(linear_out, mask\u001b[39m=\u001b[39mattention_mask, \n\u001b[1;32m     25\u001b[0m                        labels\u001b[39m=\u001b[39mlabels)\n\u001b[1;32m     26\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39meval\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     crf_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcrf\u001b[39m.\u001b[39;49mviterbi_decode(linear_out, mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[1;32m     28\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ITMO/sem1/DLtech/dl_tech_learn/lab4/crf.py:90\u001b[0m, in \u001b[0;36mCRF.viterbi_decode\u001b[0;34m(self, h, mask)\u001b[0m\n\u001b[1;32m     85\u001b[0m score_t \u001b[39m=\u001b[39m previous_score \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrans_matrix \u001b[39m+\u001b[39m h_t\n\u001b[1;32m     87\u001b[0m \u001b[39m# keep the maximum value\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39m# and point where maximum value of each sequence\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m# (batch_size, num_labels)\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m best_score, best_path \u001b[39m=\u001b[39m score_t\u001b[39m.\u001b[39;49mmax(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     91\u001b[0m score\u001b[39m.\u001b[39mappend(best_score)\n\u001b[1;32m     92\u001b[0m path\u001b[39m.\u001b[39mappend(best_path)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accum_preds = []\n",
    "accum_refs = []\n",
    "MODEL.eval()\n",
    "for batch in tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        output = MODEL(input_ids=batch['input_ids'].to(DEVICE), attention_mask=batch['attention_mask'].to(DEVICE), mode='eval')\n",
    "    preds = output\n",
    "    refs = batch['labels'].to('cpu').numpy().tolist()\n",
    "\n",
    "    accum_preds += preds\n",
    "    accum_refs += refs\n",
    "\n",
    "    print(compute_metrics(accum_preds, accum_refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = MODEL(input_ids=input_ids.to(DEVICE), attention_mask=mask.to(DEVICE), mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(output, [test_ds[20000]['labels'].cpu().numpy().tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[0])\n",
    "print(test_ds[20000]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(np.random.randint(100, size=(2,514)))\n",
    "mask = torch.ByteTensor([[1]*100 + [0]*414]*2)\n",
    "labels = torch.tensor([list(np.random.randint(3, size=100)) + [0]*414]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=input_ids, attention_mask=mask, mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzigen/miniconda3/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.09}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(output, labels.to('cpu').numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = [\n",
    "        [ID2LABEL[p] for (p, l) in zip(prediction, label)]\n",
    "        for prediction, label in zip(output, labels.to('cpu').numpy().tolist())\n",
    "    ]\n",
    "true_labels = [\n",
    "    [ID2LABEL[l] for (p, l) in zip(prediction, label.to('cpu').numpy().tolist())]\n",
    "    for prediction, label in zip(output, labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 94},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METRIC.compute(predictions=true_labels, references=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(0, 10, (10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4786)\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input_ids, mask, labels, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([346.0506, 331.8098], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(339.4282, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = encoder(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.6007, -0.3789,  1.6257,  ..., -0.2636,  0.1943, -0.9833],\n",
       "         [-0.2066,  1.4493, -0.2869,  ...,  0.4865,  1.6656,  0.2705],\n",
       "         [-0.0813,  3.3444,  0.7160,  ..., -0.0481,  1.0002, -0.3339],\n",
       "         ...,\n",
       "         [-0.5181,  1.2309,  0.9647,  ...,  0.3538,  0.5873, -0.2277],\n",
       "         [ 0.0342,  1.9868, -0.3185,  ...,  0.5481,  2.0470,  0.2225],\n",
       "         [ 0.0752,  2.7654,  0.1172,  ..., -0.3603,  0.8225,  0.3939]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0290,  0.5206, -0.6405,  ...,  0.5000, -0.3417, -0.4772]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(encoder.config.hidden_size, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_out = linear(output.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 514, 21])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = crf(l_out,labels=labels,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_out = crf.viterbi_decode(l_out,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crf_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=labels,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
